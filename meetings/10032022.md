
\tableofcontents 

## Extension to Karol's paper with asynchronous data

Please let me know if the problem I write below can be described by any 
of the following:

* totally obvious and therefore not very interesting 
* well known and so not very interesting 
* not obvious and not well known but still not a good idea to pursue
* a possible problem to pursue 

Karol considers the problem of using $p\left(\theta|x_{1:t}\right)$ to 
make inference about the parameter $\theta=\sigma$ in the discretely 
observed SDE 
\eq{
    x_{t+1} = x_t + \sigma \varepsilon
} 
where $\varepsilon$ is a normal rv.  He uses a filtering approach to 
build an online model of $p(\sigma|x_{1:t})$.  

If we were to do similar for a vol surface (either implied vols, local 
vols etc) we will be looking at a multidimensional version where we model 
$p(\theta|\mb{x}_{1:t})$.  Perhaps the dimension of $\mb{x}_{1:t}$ is 
$K \times T$ where $K$ is number of strikes and $T$ the number of expiries.
In the finance/econometrics literature, asynchronous seems to always refer 
to data observed at irregularly spaced time intervals - ie we would observe 
the sequence $\left\{ \mb{x}_1, \mb{x}_2, \hdots, \mb{x}_t\right\}$ where 
the time intervals between each are different.  

However I was thinking of *asynchronous* as the case where not only is data 
observed at irregular time intervals, but in addition not all components of 
$\mb{x}$_t are observed at once.  This is a more realistic model in eg the 
vol surface example, where components of $\mb{x}_t$ will be related to options 
at different strikes/expiry and we recieve new information about $\mb{x}_t$ 
one component at a time.  

A toy example would be Karol's model but in 2D ie 
\eq{ d\mb{z} = \Sigma \; d\mb{B} \nonumber }
where $\mb{z}_t=\left(x_t, y_t\right)$ and we want to make inference about
the elements of the matrix $\Sigma$. Instead of observing a sequence 
$\left\{ \mb{z}_1, \mb{z}_2, \hdots, \mb{z}_t\right\}$ we observe some 
sequence like $\left\{ x_1, x_2, y_3, x_4, y_5, \hdots \right\}$ etc.
Given $\mb{z}_{t}$ and then a newly observed $x_t$ the filtering approach 
might be to

* do standard particle filtering but use the marginal 
\eq{
    p(x_{t+1}|\theta,\mb{z}_t) = \int p(x_{t+1},y_{t+1}|\theta,\mb{z}_t) 
    p(y_{t+1}|\theta,\mb{z}_t) d y_{t+1} \nonumber
}
where this integral is likely very efficient as a summation across one 
dimension of the particle approximation
* use the updated marginal $p(x_{t+1}|\theta,\mb{z}_t)$ to reconstruct 
the joint distribution (I'm not sure what notation to use - what is the
time index for this guy $\left(x_{t+1},y_t\right)$?).

The main problem a priori is step 2 above.  There is probably no unique 
way to recover the joint distribution (I suspect there are an infinite 
number of joint distributions which can generate a specific marginal). 
Perhaps a start would be to compute a new joint distribution whose marginal 
matches your newly updated marginal (there are infinite number of these) but 
is *minimally different* (perhaps as measured by KS statistic) from your 
starting joint distribution.  I don't know much about this problem perhaps
this is a well established problem?

\newpage 

## Filtering for a Volatility Surface 

Assume we are running a filter for options on an underlying with 
$K$ strikes and $T$ expiries.  This might be an implied surface, a 
local vol surface, or perhaps even a price surface we might be using to
construct the local vol surface.  We have a dynamic system for $\mb{x}_t$ 
with dimension $K \times T$ and we are interested in making 
inference about some parameters $\theta$.  I have removed the bold 
font on $x_t$ hereafter but I am still referring to a multidimensional 
model.  The filtering approach will have us calculating 
\eq{
    p(\theta^i|x_t) =  \frac{p\left(x_t|x_{t-1},\theta^i \right) 
    p\left(\theta^i | x_{t-1}\right)}{\sum p\left(x_t|x_{t-1},\theta^i \right) 
    p\left(\theta^i |x_{t-1} \right)}\nonumber 
}

The point where I was stuck was thinking about what $p\left(x_t|x_{t-1},\theta^i \right)$
might look like.  At first I was thinking about this in the context of the
local volatility surface, when I was thinking about if it were possible to 
recognise the Dupire equation as a Fokker-Planck equation, and use it to 
specify what transitions $x_{t-1} \rightarrow x_t$ might look like?  This
lead me to think about **Thought Number 3** below, but then I found various
other authors have already thought of that.  After that though, I came across 
an interesting paper by Cont Et Al 2002 (Stochastic Models of Implied Volatility
Surfaces).  In it they

* review statistical properties of implied vol surfaces
* propose a stochastic model for the joint evolution of the vol surface
and underlying. See pg 366 Section 3 for the model specs.

Essentially it is a factor model using a mean reverting OU process.  They
refer to the model as *The structure of the model allows for easy estimation 
of the parameters from historical data* but we could use it for online filtering.  I 
haven't done an exhaustive search, but I have not seen it done.

\newpage 

## Local Volatility Calibration

While thinking about whether I could use the Dupire equation to get information
about transitions, I essentially thought of doing the calibration problem - ie
plug local vol functions $\sigma(k,t;\theta)$ into the Dupire PDE and solve 
numerically, until we find a *best* $\theta$.  But I see a lot of people have 
looked into this already, for example all the way back in Coleman Et Al 1998 
(Reconstructing the Unknown Local Volatility Function) which is a nicely written
paper.  Again I found Hamida and Cont 2013 do the optimisation using a genetic
algorithm (Recovering volatility from option prices by evolutionary optimization)
which is super interesting.  This made me think/notice:

* Applying the idea to models more general than diffusions is an obvious extension,
and sure enough they refer to it at the end of the paper and mention they will
look into it.  But I can't see if they ever did.  This could be pretty interesting,
and the numerics required are pretty cool.
* Is it obvious how to do this calibration approach to the local vol problem in
an online way?  This morning I came across Lindstrom Et Al 2007 (Sequential 
calibration of options), which seems nicely written and very clear.  This paper may 
provide a framework for how to write the local vol calibration problem as an online 
filtering problem.  They use various Kalman filters but I need to read this paper 
more carefully and think about it.